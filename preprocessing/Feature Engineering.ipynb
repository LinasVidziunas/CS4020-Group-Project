{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickle import dump\n",
    "\n",
    "import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_path: pathlib.Path = pathlib.Path.cwd().parent / \"datasets\" / \"raw\" / \"combined.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df: pd.DataFrame = pd.read_parquet(combined_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AirTime              27.030472\n",
       "TaxiIn               25.730429\n",
       "TaxiOut              25.718116\n",
       "Tail_Number          25.395022\n",
       "ArrDelay              2.261258\n",
       "ActualElapsedTime     2.260889\n",
       "ArrTime               2.220742\n",
       "DepDelay              2.021100\n",
       "DepTime               2.020133\n",
       "Distance              0.136387\n",
       "OriginState           0.027382\n",
       "OriginCityName        0.027382\n",
       "DestCityName          0.026189\n",
       "DestState             0.026189\n",
       "CRSElapsedTime        0.017433\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing: pd.Series = preprocessing.percentage_missing_values_per_column(data_df)\n",
    "percent_missing[percent_missing > 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 3 features containing the most missing values, are about 25% empty.\n",
    "Since 25% is a substantial amount of data, we ..,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(['AirTime', 'TaxiIn', 'TaxiOut', 'Tail_Number'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit the minimum arrival and departure delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['ArrDelay'] = data_df['ArrDelay'].apply(lambda x: 0 if x < 0 else x)\n",
    "data_df['DepDelay'] = data_df['DepDelay'].apply(lambda x: 0 if x < 0 else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we do not have any missing values, we convert the column types to reduce memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 144482939 entries, 0 to 148108239\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Dtype   \n",
      "---  ------             -----   \n",
      " 0   Airline            category\n",
      " 1   Origin             category\n",
      " 2   Year               int64   \n",
      " 3   Distance           float64 \n",
      " 4   Cancelled          bool    \n",
      " 5   DestState          category\n",
      " 6   ActualElapsedTime  float64 \n",
      " 7   OriginState        category\n",
      " 8   ArrTime            float64 \n",
      " 9   DestCityName       category\n",
      " 10  CRSElapsedTime     float64 \n",
      " 11  DepTime            float64 \n",
      " 12  DepDelay           float64 \n",
      " 13  Diverted           bool    \n",
      " 14  CRSArrTime         int64   \n",
      " 15  DayOfWeek          int64   \n",
      " 16  OriginCityName     category\n",
      " 17  ArrDelay           float64 \n",
      " 18  Dest               category\n",
      " 19  Month              int64   \n",
      " 20  CRSDepTime         int64   \n",
      " 21  DayofMonth         int64   \n",
      "dtypes: bool(2), category(7), float64(7), int64(6)\n",
      "memory usage: 16.8 GB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnecessary float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns: pd.Index = data_df.select_dtypes(include=['float']).columns\n",
    "\n",
    "for column in float_columns:\n",
    "    if (data_df[column] == data_df[column].astype('int64')).all():\n",
    "        data_df[column] = data_df[column].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 144482939 entries, 0 to 148108239\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Dtype   \n",
      "---  ------             -----   \n",
      " 0   Airline            category\n",
      " 1   Origin             category\n",
      " 2   Year               int64   \n",
      " 3   Distance           int64   \n",
      " 4   Cancelled          bool    \n",
      " 5   DestState          category\n",
      " 6   ActualElapsedTime  int64   \n",
      " 7   OriginState        category\n",
      " 8   ArrTime            int64   \n",
      " 9   DestCityName       category\n",
      " 10  CRSElapsedTime     int64   \n",
      " 11  DepTime            int64   \n",
      " 12  DepDelay           int64   \n",
      " 13  Diverted           bool    \n",
      " 14  CRSArrTime         int64   \n",
      " 15  DayOfWeek          int64   \n",
      " 16  OriginCityName     category\n",
      " 17  ArrDelay           int64   \n",
      " 18  Dest               category\n",
      " 19  Month              int64   \n",
      " 20  CRSDepTime         int64   \n",
      " 21  DayofMonth         int64   \n",
      "dtypes: bool(2), category(7), int64(13)\n",
      "memory usage: 16.8 GB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Int columns to fewer byte ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_columns: pd.Index = data_df.select_dtypes(include=['int']).columns\n",
    "\n",
    "for column in integer_columns:\n",
    "    max_size = data_df[column].max()\n",
    "    min_size = data_df[column].min()\n",
    "\n",
    "    \n",
    "    if min_size >= 0:\n",
    "        if max_size <= np.iinfo(np.uint8).max:\n",
    "            data_df[column] = data_df[column].astype('uint8')\n",
    "        elif max_size <= np.iinfo(np.uint16).max:\n",
    "            data_df[column] = data_df[column].astype('uint16')\n",
    "        elif max_size <= np.iinfo(np.uint32).max:\n",
    "            data_df[column] = data_df[column].astype('uint32')\n",
    "        elif max_size <= np.iinfo(np.uint64).max:\n",
    "            data_df[column] = data_df[column].astype('uint64')\n",
    "    else:\n",
    "        if max_size <= np.iinfo(np.int8).max and min_size >= np.iinfo(np.int8).min: \n",
    "            data_df[column] = data_df[column].astype('int8')\n",
    "        elif max_size <= np.iinfo(np.int16).max and min_size >= np.iinfo(np.int16).min:\n",
    "            data_df[column] = data_df[column].astype('int16')\n",
    "        elif max_size <= np.iinfo(np.int32).max and min_size >= np.iinfo(np.int32).min:\n",
    "            data_df[column] = data_df[column].astype('int32')\n",
    "        elif max_size <= np.iinfo(np.int64).max and min_size >= np.iinfo(np.int64).min:\n",
    "            data_df[column] = data_df[column].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 144482939 entries, 0 to 148108239\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Dtype   \n",
      "---  ------             -----   \n",
      " 0   Airline            category\n",
      " 1   Origin             category\n",
      " 2   Year               uint16  \n",
      " 3   Distance           uint16  \n",
      " 4   Cancelled          bool    \n",
      " 5   DestState          category\n",
      " 6   ActualElapsedTime  int16   \n",
      " 7   OriginState        category\n",
      " 8   ArrTime            uint16  \n",
      " 9   DestCityName       category\n",
      " 10  CRSElapsedTime     int16   \n",
      " 11  DepTime            uint16  \n",
      " 12  DepDelay           uint16  \n",
      " 13  Diverted           bool    \n",
      " 14  CRSArrTime         uint16  \n",
      " 15  DayOfWeek          uint8   \n",
      " 16  OriginCityName     category\n",
      " 17  ArrDelay           uint16  \n",
      " 18  Dest               category\n",
      " 19  Month              uint8   \n",
      " 20  CRSDepTime         uint16  \n",
      " 21  DayofMonth         uint8   \n",
      "dtypes: bool(2), category(7), int16(2), uint16(8), uint8(3)\n",
      "memory usage: 5.9 GB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're planning to use random forest for the regression task, we encode the categorical columns using LabelEncoder as opposed to OneHotEncoder which should be used if the regression was performed by a NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Airline' has 47 unique values.\n",
      "Column 'Origin' has 422 unique values.\n",
      "Column 'DestState' has 54 unique values.\n",
      "Column 'OriginState' has 54 unique values.\n",
      "Column 'DestCityName' has 441 unique values.\n",
      "Column 'OriginCityName' has 442 unique values.\n",
      "Column 'Dest' has 420 unique values.\n"
     ]
    }
   ],
   "source": [
    "categorical_columns: list[str] = data_df.select_dtypes(include=['category']).columns.to_list()\n",
    "\n",
    "for column in categorical_columns:\n",
    "    print(f\"Column '{column}' has {len(data_df[column].unique())} unique values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    data_df[feature] = label_encoder.fit_transform(data_df[feature])\n",
    "    dump(label_encoder, open('../datasets/processed/label_encoder_' + feature + '.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the label encoder for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(label_encoder, open('../datasets/processed/label_encoder.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train, Val, Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.1, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=len(test_df), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(pathlib.Path.cwd().parent / \"datasets\" / \"processed\" / \"train.parquet\")\n",
    "val_df.to_parquet(pathlib.Path.cwd().parent / \"datasets\" / \"processed\" / \"val.parquet\")\n",
    "test_df.to_parquet(pathlib.Path.cwd().parent / \"datasets\" / \"processed\" / \"test.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
