{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickle import dump\n",
    "\n",
    "import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_path: pathlib.Path = pathlib.Path.cwd().parent / \"datasets\" / \"raw\" / \"combined.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df: pd.DataFrame = pd.read_parquet(combined_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AirTime              2.703047e+01\n",
       "TaxiIn               2.573043e+01\n",
       "TaxiOut              2.571812e+01\n",
       "Tail_Number          2.539502e+01\n",
       "ArrDelay             2.261258e+00\n",
       "ActualElapsedTime    2.260889e+00\n",
       "ArrTime              2.220742e+00\n",
       "DepDelay             2.021100e+00\n",
       "DepTime              2.020133e+00\n",
       "Distance             1.363867e-01\n",
       "OriginCityName       2.738200e-02\n",
       "OriginState          2.738200e-02\n",
       "DestState            2.618895e-02\n",
       "DestCityName         2.618895e-02\n",
       "CRSElapsedTime       1.743252e-02\n",
       "DestAirport          6.751819e-07\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing: pd.Series = preprocessing.percentage_missing_values_per_column(data_df)\n",
    "percent_missing[percent_missing > 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 3 features containing the most missing values, are about 25% empty.\n",
    "Since 25% is a substantial amount of data, we ..,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(['AirTime', 'TaxiIn', 'TaxiOut', 'Tail_Number'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit the minimum arrival and departure delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['ArrDelay'] = data_df['ArrDelay'].apply(lambda x: 0 if x < 0 else x)\n",
    "data_df['DepDelay'] = data_df['DepDelay'].apply(lambda x: 0 if x < 0 else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we do not have any missing values, we convert the column types to reduce memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 144482939 entries, 0 to 148108239\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Dtype   \n",
      "---  ------             -----   \n",
      " 0   DayOfWeek          int64   \n",
      " 1   DepDelay           float64 \n",
      " 2   DepTime            float64 \n",
      " 3   Origin             category\n",
      " 4   DayofMonth         int64   \n",
      " 5   CRSDepTime         int64   \n",
      " 6   ArrTime            float64 \n",
      " 7   Diverted           bool    \n",
      " 8   Airline            category\n",
      " 9   Distance           float64 \n",
      " 10  Cancelled          bool    \n",
      " 11  ActualElapsedTime  float64 \n",
      " 12  OriginCityName     category\n",
      " 13  OriginState        category\n",
      " 14  CRSElapsedTime     float64 \n",
      " 15  DestCityName       category\n",
      " 16  Month              int64   \n",
      " 17  ArrDelay           float64 \n",
      " 18  DestAirport        category\n",
      " 19  DestState          category\n",
      " 20  Dest               category\n",
      " 21  OriginAirport      category\n",
      " 22  Year               int64   \n",
      " 23  CRSArrTime         int64   \n",
      "dtypes: bool(2), category(9), float64(7), int64(6)\n",
      "memory usage: 17.4 GB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnecessary float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns: pd.Index = data_df.select_dtypes(include=['float']).columns\n",
    "\n",
    "for column in float_columns:\n",
    "    if (data_df[column] == data_df[column].astype('int64')).all():\n",
    "        data_df[column] = data_df[column].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 144482939 entries, 0 to 148108239\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Dtype   \n",
      "---  ------             -----   \n",
      " 0   DayOfWeek          int64   \n",
      " 1   DepDelay           int64   \n",
      " 2   DepTime            int64   \n",
      " 3   Origin             category\n",
      " 4   DayofMonth         int64   \n",
      " 5   CRSDepTime         int64   \n",
      " 6   ArrTime            int64   \n",
      " 7   Diverted           bool    \n",
      " 8   Airline            category\n",
      " 9   Distance           int64   \n",
      " 10  Cancelled          bool    \n",
      " 11  ActualElapsedTime  int64   \n",
      " 12  OriginCityName     category\n",
      " 13  OriginState        category\n",
      " 14  CRSElapsedTime     int64   \n",
      " 15  DestCityName       category\n",
      " 16  Month              int64   \n",
      " 17  ArrDelay           int64   \n",
      " 18  DestAirport        category\n",
      " 19  DestState          category\n",
      " 20  Dest               category\n",
      " 21  OriginAirport      category\n",
      " 22  Year               int64   \n",
      " 23  CRSArrTime         int64   \n",
      "dtypes: bool(2), category(9), int64(13)\n",
      "memory usage: 17.4 GB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Int columns to fewer byte ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_columns: pd.Index = data_df.select_dtypes(include=['int']).columns\n",
    "\n",
    "for column in integer_columns:\n",
    "    max_size = data_df[column].max()\n",
    "    min_size = data_df[column].min()\n",
    "\n",
    "    \n",
    "    if min_size >= 0:\n",
    "        if max_size <= np.iinfo(np.uint8).max:\n",
    "            data_df[column] = data_df[column].astype('uint8')\n",
    "        elif max_size <= np.iinfo(np.uint16).max:\n",
    "            data_df[column] = data_df[column].astype('uint16')\n",
    "        elif max_size <= np.iinfo(np.uint32).max:\n",
    "            data_df[column] = data_df[column].astype('uint32')\n",
    "        elif max_size <= np.iinfo(np.uint64).max:\n",
    "            data_df[column] = data_df[column].astype('uint64')\n",
    "    else:\n",
    "        if max_size <= np.iinfo(np.int8).max and min_size >= np.iinfo(np.int8).min: \n",
    "            data_df[column] = data_df[column].astype('int8')\n",
    "        elif max_size <= np.iinfo(np.int16).max and min_size >= np.iinfo(np.int16).min:\n",
    "            data_df[column] = data_df[column].astype('int16')\n",
    "        elif max_size <= np.iinfo(np.int32).max and min_size >= np.iinfo(np.int32).min:\n",
    "            data_df[column] = data_df[column].astype('int32')\n",
    "        elif max_size <= np.iinfo(np.int64).max and min_size >= np.iinfo(np.int64).min:\n",
    "            data_df[column] = data_df[column].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 144482939 entries, 0 to 148108239\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Dtype   \n",
      "---  ------             -----   \n",
      " 0   DayOfWeek          uint8   \n",
      " 1   DepDelay           uint16  \n",
      " 2   DepTime            uint16  \n",
      " 3   Origin             category\n",
      " 4   DayofMonth         uint8   \n",
      " 5   CRSDepTime         uint16  \n",
      " 6   ArrTime            uint16  \n",
      " 7   Diverted           bool    \n",
      " 8   Airline            category\n",
      " 9   Distance           uint16  \n",
      " 10  Cancelled          bool    \n",
      " 11  ActualElapsedTime  int16   \n",
      " 12  OriginCityName     category\n",
      " 13  OriginState        category\n",
      " 14  CRSElapsedTime     int16   \n",
      " 15  DestCityName       category\n",
      " 16  Month              uint8   \n",
      " 17  ArrDelay           uint16  \n",
      " 18  DestAirport        category\n",
      " 19  DestState          category\n",
      " 20  Dest               category\n",
      " 21  OriginAirport      category\n",
      " 22  Year               uint16  \n",
      " 23  CRSArrTime         uint16  \n",
      "dtypes: bool(2), category(9), int16(2), uint16(8), uint8(3)\n",
      "memory usage: 6.5 GB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're planning to use random forest for the regression task, we encode the categorical columns using LabelEncoder as opposed to OneHotEncoder which should be used if the regression was performed by a NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Origin' has 422 unique values.\n",
      "Column 'Airline' has 47 unique values.\n",
      "Column 'OriginCityName' has 442 unique values.\n",
      "Column 'OriginState' has 54 unique values.\n",
      "Column 'DestCityName' has 441 unique values.\n",
      "Column 'DestAirport' has 718 unique values.\n",
      "Column 'DestState' has 54 unique values.\n",
      "Column 'Dest' has 420 unique values.\n",
      "Column 'OriginAirport' has 723 unique values.\n"
     ]
    }
   ],
   "source": [
    "categorical_columns: list[str] = data_df.select_dtypes(include=['category']).columns.to_list()\n",
    "\n",
    "for column in categorical_columns:\n",
    "    print(f\"Column '{column}' has {len(data_df[column].unique())} unique values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    data_df[feature] = label_encoder.fit_transform(data_df[feature])\n",
    "    dump(label_encoder, open('../datasets/processed/label_encoder_' + feature + '.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train, Val, Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.1, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=len(test_df), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(pathlib.Path.cwd().parent / \"datasets\" / \"processed\" / \"train.parquet\")\n",
    "val_df.to_parquet(pathlib.Path.cwd().parent / \"datasets\" / \"processed\" / \"val.parquet\")\n",
    "test_df.to_parquet(pathlib.Path.cwd().parent / \"datasets\" / \"processed\" / \"test.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
